{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanyavijj/edtech-project/blob/main/msvd_Untitled33_CLEANED.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xW8SIAIGbDA1"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-mAcUDUjMka"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import tarfile\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from transformers import CLIPModel, CLIPProcessor, CLIPTokenizer\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Js9vWKohJH3"
      },
      "outputs": [],
      "source": [
        "# Define Paths - Change This Based on Your Drive Location\n",
        "base_folder = \"/content/drive/MyDrive/iit data/\"\n",
        "tar_file = os.path.join(base_folder, \"YouTubeClips.tar\")\n",
        "annotation_file = os.path.join(base_folder, \"annotations.txt\")\n",
        "frame_output_folder = os.path.join(base_folder, \"frames\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9o-PkIG4jbL9"
      },
      "outputs": [],
      "source": [
        "# Extract TAR File if Not Already Extracted\n",
        "if not os.path.exists(frame_output_folder):\n",
        "    os.makedirs(frame_output_folder, exist_ok=True)\n",
        "    with tarfile.open(tar_file, \"r\") as tar:\n",
        "        tar.extractall(path=frame_output_folder)\n",
        "    print(f\"Extracted TAR file to {frame_output_folder}\")\n",
        "else:\n",
        "    print(\"Frames folder already exists.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yT17zNEGjbId"
      },
      "outputs": [],
      "source": [
        "#  Extract Frames from Videos\n",
        "def extract_frames(video_folder, output_folder, fps=1):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    for video_file in os.listdir(video_folder):\n",
        "        if video_file.endswith(\".mp4\") or video_file.endswith(\".avi\"):\n",
        "            video_path = os.path.join(video_folder, video_file)\n",
        "            cap = cv2.VideoCapture(video_path)\n",
        "            frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "            frame_id = 0\n",
        "\n",
        "            while cap.isOpened():\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "                if frame_id % frame_rate == 0:  # Extract 1 frame per second\n",
        "                    frame_filename = os.path.join(output_folder, f\"{video_file.split('.')[0]}_frame_{frame_id}.jpg\")\n",
        "                    cv2.imwrite(frame_filename, frame)\n",
        "                frame_id += 1\n",
        "\n",
        "            cap.release()\n",
        "            print(f\" Frames extracted for {video_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQ6t2PDmjbGR"
      },
      "outputs": [],
      "source": [
        "#  Run Frame Extraction\n",
        "extract_frames(frame_output_folder, frame_output_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4hG-FHakjtX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "print(os.listdir(\"/content/drive/MyDrive/iit data/\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DE1l8FTk2ZT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "frame_output_folder = \"/content/drive/MyDrive/iit data/frames\"\n",
        "frame_files = os.listdir(frame_output_folder)\n",
        "\n",
        "if len(frame_files) == 0:\n",
        "    print(\" No frames found! Frame extraction failed.\")\n",
        "else:\n",
        "    print(f\" {len(frame_files)} frames found.\")\n",
        "    print(\"First 5 frame files:\", frame_files[:5])  # Print first few extracted frames\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOAtxZ94lLbE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "video_folder = \"/content/drive/MyDrive/iit data/videos\"\n",
        "videos = os.listdir(video_folder)\n",
        "\n",
        "if len(videos) == 0:\n",
        "    print(\" No videos found! Extraction failed.\")\n",
        "else:\n",
        "    print(f\" {len(videos)} videos found.\")\n",
        "    print(\" First 5 videos:\", videos[:5])  # Show first few videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "973A85MZlY6m"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "video_path = \"/content/drive/MyDrive/iit data/videos/YouTubeClips\"\n",
        "\n",
        "if os.path.isdir(video_path):\n",
        "    print(\"'YouTubeClips' is a folder. Checking contents...\")\n",
        "    print(os.listdir(video_path)[:5])  # Show first 5 files inside\n",
        "elif os.path.isfile(video_path):\n",
        "    print(\" 'YouTubeClips' is a single file! Needs extraction.\")\n",
        "else:\n",
        "    print(\" 'YouTubeClips' does not exist.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gw7QpVuYjbEC"
      },
      "outputs": [],
      "source": [
        "#  Check Extracted Frames\n",
        "frame_files = os.listdir(frame_output_folder)\n",
        "if len(frame_files) == 0:\n",
        "    print(\"No frames found! Check extraction process.\")\n",
        "else:\n",
        "    print(f\"{len(frame_files)} frames found.\")\n",
        "    print(frame_files[:5])  # Print first 5 frame names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbkICXSaljWn"
      },
      "outputs": [],
      "source": [
        "video_folder = \"/content/drive/MyDrive/iit data/videos/YouTubeClips\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDpxJWtFlnw8"
      },
      "outputs": [],
      "source": [
        "extract_frames(video_folder, frame_output_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50IDT0b2jbBr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def create_caption_mapping(annotation_file, frame_output_folder):\n",
        "    # Step 1: Load all frame names once (FAST lookup with a dictionary)\n",
        "    frame_dict = {os.path.splitext(frame)[0]: frame for frame in os.listdir(frame_output_folder)}\n",
        "    captions = {}\n",
        "\n",
        "    # Step 2: Process annotations\n",
        "    with open(annotation_file, \"r\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split(\"\\t\")\n",
        "            if len(parts) >= 2:\n",
        "                video_file = parts[0].strip()\n",
        "                caption = parts[1].strip()\n",
        "                frame_prefix = os.path.splitext(video_file)[0]\n",
        "\n",
        "                # Instead of looping, just check if frame exists in dictionary\n",
        "                if frame_prefix in frame_dict:\n",
        "                    captions[frame_dict[frame_prefix]] = caption\n",
        "\n",
        "    print(f\"Captions mapped: {len(captions)} frames found.\")\n",
        "    return captions\n",
        "\n",
        "# Run function\n",
        "captions = create_caption_mapping(\"/content/drive/MyDrive/iit data/annotations.txt\",\n",
        "                                  \"/content/drive/MyDrive/iit data/frames\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZrboeuwja_i"
      },
      "outputs": [],
      "source": [
        "# Save Captions to CSV\n",
        "df = pd.DataFrame(list(captions.items()), columns=[\"Frame\", \"Caption\"])\n",
        "df.to_csv(os.path.join(base_folder, \"captions.csv\"), index=False)\n",
        "print(f\"Captions saved to {base_folder}captions.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_ppdr4ShJEd"
      },
      "outputs": [],
      "source": [
        "# Load CLIP Model\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28ctC7urhJB9"
      },
      "outputs": [],
      "source": [
        "# Preprocessing Functions\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    img_tensor = transform(img).unsqueeze(0)  # Add batch dimension\n",
        "    return img_tensor\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = tokenizer(text, return_tensors=\"pt\")[\"input_ids\"]\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtZ1EJfVboFx"
      },
      "outputs": [],
      "source": [
        "# Image Search Function\n",
        "def image_search(query, frame_folder=frame_output_folder, top_k=5):\n",
        "    query_tokens = preprocess_text(query)\n",
        "    text_features = model.get_text_features(input_ids=query_tokens)\n",
        "\n",
        "    frame_scores = []\n",
        "\n",
        "    for frame in os.listdir(frame_folder):\n",
        "        if frame.endswith(\".jpg\"):\n",
        "            img_path = os.path.join(frame_folder, frame)\n",
        "            img_tensor = preprocess_image(img_path)\n",
        "            image_features = model.get_image_features(pixel_values=img_tensor)\n",
        "            similarity = torch.cosine_similarity(image_features, text_features)\n",
        "            frame_scores.append((frame, similarity.item(), img_path))\n",
        "\n",
        "    frame_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "    top_results = frame_scores[:top_k]\n",
        "\n",
        "    print(\"\\n**Top Search Results:**\")\n",
        "    for frame, score, img_path in top_results:\n",
        "        print(f\" {frame} - Similarity: {score:.4f} - Path: {img_path}\")\n",
        "\n",
        "        try:\n",
        "            img = Image.open(img_path)\n",
        "            display(img)  # Show image inside Colab\n",
        "        except Exception as e:\n",
        "            print(f\"Error displaying image: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBRrCm0RboB3"
      },
      "outputs": [],
      "source": [
        "# Run an Example Search Query\n",
        "image_search(\"A person playing guitar\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}